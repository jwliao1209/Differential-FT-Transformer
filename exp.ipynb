{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from src.metric import cls_eval_funs, reg_eval_funs\n",
    "from src.trainer import Trainer\n",
    "from src.utils import load_pkl_data, set_random_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    data_dir = '/home/jiawei/Desktop/github/DOFEN/tabular-benchmark/tabular_benchmark_data'\n",
    "    data_id = '361061'\n",
    "    n_epoch = 300\n",
    "    batch_size = 256\n",
    "    target_transform = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from src.models.base import BaseClassifier, BaseRegressor\n",
    "from src.models.layers import ResidualLayer, ReGLU\n",
    "\n",
    "\n",
    "class Reshape(nn.Module):\n",
    "    def __init__(self, *args: int) -> None:\n",
    "        super(Reshape, self).__init__()\n",
    "        self.shape = args\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return x.reshape(self.shape)\n",
    "\n",
    "\n",
    "class FastGroupConv1d(nn.Conv1d):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.fast_mode = kwargs.pop('fast_mode')\n",
    "        nn.Conv1d.__init__(self, *args, **kwargs)\n",
    "        if self.groups > self.fast_mode:\n",
    "            self.weight = nn.Parameter(\n",
    "                self.weight.reshape(\n",
    "                    self.groups, self.out_channels // self.groups, self.in_channels // self.groups, 1\n",
    "                ).permute(3, 0, 2, 1)\n",
    "            )\n",
    "            self.bias = nn.Parameter(\n",
    "                self.bias.unsqueeze(0).unsqueeze(-1)\n",
    "            )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        if self.groups > self.fast_mode:\n",
    "            x = x.reshape(-1, self.groups, self.in_channels // self.groups, 1)\n",
    "            return (x * self.weight).sum(2, keepdims=True).permute(0, 1, 3, 2).reshape(-1, self.out_channels, 1) + self.bias\n",
    "        else:\n",
    "            return self._conv_forward(x, self.weight, self.bias)\n",
    "\n",
    "\n",
    "class ConditionGeneration(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        category_column_count: List[int],\n",
    "        n_cond: int = 128,\n",
    "        n_hidden: int = 4,\n",
    "        categorical_optimized: bool = False,\n",
    "        fast_mode: int = 64,\n",
    "    ):\n",
    "        super(ConditionGeneration, self).__init__()\n",
    "        self.fast_mode = fast_mode\n",
    "        self.categorical_optimized = categorical_optimized\n",
    "\n",
    "        index_info = self.extract_feature_metadata(category_column_count)\n",
    "        self.numerical_index = index_info['numerical_index']\n",
    "        self.categorical_index = index_info['categorical_index']\n",
    "        self.categorical_count = index_info['categorical_count']\n",
    "\n",
    "        categorical_offset = torch.tensor([0] + np.cumsum(self.categorical_count).tolist()[:-1]).long()\n",
    "        self.register_buffer('categorical_offset', categorical_offset)\n",
    "\n",
    "        self.n_cond = n_cond\n",
    "        self.n_hidden = n_hidden\n",
    "        self.phi_1 = self.get_phi_1()\n",
    "\n",
    "    def extract_feature_metadata(self, category_column_count: List[int]) -> Dict[str, List[int]]:\n",
    "        numerical_index = [i for i, count in enumerate(category_column_count) if count == -1]\n",
    "        categorical_index = [i for i, count in enumerate(category_column_count) if count != -1]\n",
    "        categorical_count = [count for count in category_column_count if count != -1]\n",
    "        return {\n",
    "            'numerical_index': numerical_index,\n",
    "            'categorical_index': categorical_index,\n",
    "            'categorical_count': categorical_count,\n",
    "        }\n",
    "\n",
    "    def get_phi_1(self) -> nn.ModuleDict:\n",
    "        phi_1 = nn.ModuleDict()\n",
    "        if len(self.numerical_index):\n",
    "            phi_1['num'] = nn.Sequential(\n",
    "                # input = (b, n_num_col)\n",
    "                # output = (b, n_num_col, n_cond)\n",
    "                Reshape(-1, len(self.numerical_index), 1),\n",
    "                FastGroupConv1d(\n",
    "                    len(self.numerical_index),\n",
    "                    len(self.numerical_index) * self.n_cond * self.n_hidden,\n",
    "                    kernel_size=1,\n",
    "                    groups=len(self.numerical_index),\n",
    "                    fast_mode=self.fast_mode\n",
    "                ), # (b, n_num_col, 1) -> (b, n_num_col * n_cond, 1)\n",
    "                # nn.Sigmoid(),\n",
    "                Reshape(-1, len(self.numerical_index), self.n_cond, self.n_hidden)\n",
    "            )\n",
    "        if len(self.categorical_index):\n",
    "            phi_1['cat'] = nn.ModuleDict()\n",
    "            phi_1['cat']['embedder'] = nn.Embedding(sum(self.categorical_count), self.n_cond * self.n_hidden)            \n",
    "            phi_1['cat']['mapper'] = nn.Sequential(\n",
    "                # input = (b, n_cat_col, n_cond)\n",
    "                # output = (b, n_cat_col, n_cond)\n",
    "                Reshape(-1, len(self.categorical_index) * self.n_cond  * self.n_hidden, 1),\n",
    "                nn.GroupNorm(len(self.categorical_index), len(self.categorical_index) * self.n_cond  * self.n_hidden),\n",
    "                FastGroupConv1d(\n",
    "                    len(self.categorical_index) * self.n_cond  * self.n_hidden,\n",
    "                    len(self.categorical_index) * self.n_cond  * self.n_hidden,\n",
    "                    kernel_size=1,\n",
    "                    groups=len(self.categorical_index) * self.n_cond  * self.n_hidden if self.categorical_optimized else len(self.categorical_index),\n",
    "                    fast_mode=self.fast_mode),                \n",
    "                nn.Sigmoid(),\n",
    "                Reshape(-1, len(self.categorical_index), self.n_cond, self.n_hidden)\n",
    "            )\n",
    "        return phi_1\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        M = []\n",
    "\n",
    "        if len(self.numerical_index):\n",
    "            num_x = x[:, self.numerical_index].float()\n",
    "            num_sample_emb = self.phi_1['num'](num_x)\n",
    "            M.append(num_sample_emb)\n",
    "\n",
    "        if len(self.categorical_index):\n",
    "            cat_x = x[:, self.categorical_index].long() + self.cat_offset\n",
    "            cat_sample_emb = self.phi_1['cat']['mapper'](self.phi_1['cat']['embedder'](cat_x))\n",
    "            M.append(cat_sample_emb)\n",
    "\n",
    "        M = torch.cat(M, dim=1) # (b, n_col, n_cond, n_hidden)\n",
    "        M = M.permute(0, 2, 1, 3) # (b, n_cond, n_col, n_hidden)\n",
    "        return M\n",
    "\n",
    "\n",
    "class rODTConstruction(nn.Module):\n",
    "    def __init__(self, n_cond: int, n_col: int, d: int) -> None:\n",
    "        super().__init__()\n",
    "        self.permutator = torch.rand(n_cond * n_col).argsort(-1)\n",
    "        self.d = d\n",
    "\n",
    "    def forward(self, M: torch.Tensor) -> torch.Tensor:\n",
    "        b, _, _, embed_dim = M.shape\n",
    "        return M.reshape(b, -1, embed_dim)[:, self.permutator, :].reshape(b, -1, self.d, embed_dim)\n",
    "\n",
    "\n",
    "class rODTForestConstruction(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_col: int,\n",
    "        n_rodt: int,\n",
    "        n_cond: int,\n",
    "        n_estimator: int,\n",
    "        n_head: int = 1,\n",
    "        n_hidden: int = 128,\n",
    "        n_forest: int = 100,\n",
    "        dropout: float = 0.0,\n",
    "        fast_mode: int = 64,\n",
    "        device = torch.device('cuda')\n",
    "    ) -> None:\n",
    "\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.n_estimator = n_estimator\n",
    "        self.n_forest = n_forest\n",
    "        self.n_rodt = n_rodt\n",
    "        self.n_head = n_head\n",
    "        self.n_hidden = n_hidden\n",
    "\n",
    "        self.sample_without_replacement_eval = self.get_sample_without_replacement()\n",
    "\n",
    "    def get_sample_without_replacement(self) -> torch.Tensor:\n",
    "        return torch.rand(self.n_forest, self.n_rodt, device=self.device).argsort(-1)[:, :self.n_estimator]\n",
    "\n",
    "    def forward(self, w, E) -> torch.Tensor:\n",
    "        # w: (b, n_rodt, 1)\n",
    "        # E: (b, n_rodt, n_hidden)\n",
    "    \n",
    "        sample_without_replacement = self.get_sample_without_replacement() if self.training else self.sample_without_replacement_eval\n",
    "\n",
    "        w_prime = w[:, sample_without_replacement].softmax(-2) # (b, n_forest, n_rodt, 1)\n",
    "        E_prime = E[:, sample_without_replacement].reshape(\n",
    "            E.shape[0], self.n_forest, self.n_estimator, self.n_hidden\n",
    "        ) # (b, n_forest, n_rodt, n_hidden)\n",
    "\n",
    "        F = (w_prime * E_prime).sum(-2).reshape(\n",
    "            E.shape[0], self.n_forest, self.n_hidden\n",
    "        ) # (b, n_forest, n_hidden)\n",
    "        return F\n",
    "\n",
    "\n",
    "class rODTForestBagging(nn.Module):\n",
    "    def __init__(self, n_hidden: int, dropout: float, n_class: int) -> None:\n",
    "        super().__init__()\n",
    "        self.phi_3 = nn.Sequential(\n",
    "            nn.LayerNorm(n_hidden),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(n_hidden),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(n_hidden, n_class)\n",
    "        )\n",
    "\n",
    "    def forward(self, F: torch.Tensor) -> torch.Tensor:\n",
    "        return self.phi_3(F) # (b, n_forest, n_class)\n",
    "\n",
    "\n",
    "class MultiheadAttention(nn.Module):\n",
    "    def __init__(self, embed_dim: int, num_heads: int, dropout: float = 0.):\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = embed_dim // num_heads\n",
    "        self.scaling = self.head_dim ** -0.5\n",
    "        assert self.head_dim * num_heads == embed_dim, \"embed_dim must be divisible by num_heads\"\n",
    "\n",
    "        self.qw_proj = self.create_linear(embed_dim, embed_dim)\n",
    "        self.kw_proj = self.create_linear(embed_dim, embed_dim)\n",
    "        self.vw_proj = self.create_linear(embed_dim, embed_dim)\n",
    "        self.ow_proj = self.create_linear(embed_dim, 1)\n",
    "\n",
    "        self.qE_proj = self.create_linear(embed_dim, embed_dim)\n",
    "        self.kE_proj = self.create_linear(embed_dim, embed_dim)\n",
    "        self.vE_proj = self.create_linear(embed_dim, embed_dim)\n",
    "        self.oE_proj = self.create_linear(embed_dim, embed_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def create_linear(self, in_features: int, out_features: int):\n",
    "        linear = nn.Linear(in_features, out_features)\n",
    "        nn.init.xavier_uniform_(linear.weight, gain=1 / 2 ** 0.5)\n",
    "        return linear\n",
    "\n",
    "    def forward(self, query: torch.Tensor, key: torch.Tensor, value: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        query: Tensor of shape (batch_size, tgt_len, embed_dim)\n",
    "        key: Tensor of shape (batch_size, src_len, embed_dim)\n",
    "        value: Tensor of shape (batch_size, src_len, embed_dim)\n",
    "        attn_mask: Optional[Tensor] of shape (tgt_len, src_len) or (batch_size, tgt_len, src_len)\n",
    "        \"\"\"\n",
    "        batch_size, tgt_len, _ = query.size()\n",
    "        src_len = key.size(1)\n",
    "\n",
    "        # Compute w\n",
    "        qw = self.qw_proj(query)  # shape: (batch_size, tgt_len, embed_dim)\n",
    "        kw = self.kw_proj(key)    # shape: (batch_size, src_len, embed_dim)\n",
    "        vw = self.vw_proj(value)  # shape: (batch_size, src_len, 1)\n",
    "\n",
    "        # Reshape into multihead format\n",
    "        qw = qw.view(batch_size, tgt_len, self.num_heads, self.head_dim).transpose(1, 2) # shape: (batch_size, num_heads, tgt_len, head_dim)\n",
    "        kw = kw.view(batch_size, src_len, self.num_heads, self.head_dim).transpose(1, 2) # shape: (batch_size, num_heads, src_len, head_dim)\n",
    "        vw = vw.view(batch_size, src_len, self.num_heads, self.head_dim).transpose(1, 2) # shape: (batch_size, num_heads, src_len, 1)\n",
    "\n",
    "        attn_w = F.softmax(torch.matmul(qw, kw.transpose(-2, -1)) / self.scaling, dim=-1) # shape: (batch_size, num_heads, tgt_len, src_len)\n",
    "        attn_w = self.dropout(attn_w) \n",
    "        attn_w_output = torch.matmul(attn_w, vw) # shape: (batch_size, num_heads, tgt_len, head_dim)\n",
    "\n",
    "        # Reshape back to original dimensions\n",
    "        attn_w_output = attn_w_output.transpose(1, 2).contiguous().view(batch_size, tgt_len, self.embed_dim) # shape: (batch_size, tgt_len, embed_dim)\n",
    "        w_output = self.ow_proj(attn_w_output) # shape: (batch_size, tgt_len, 1)\n",
    "        w_output = w_output.mean(1)\n",
    "\n",
    "        # Compute w\n",
    "        qE = self.qE_proj(query)  # shape: (batch_size, tgt_len, embed_dim)\n",
    "        kE = self.kE_proj(key)    # shape: (batch_size, src_len, embed_dim)\n",
    "        vE = self.vE_proj(value)  # shape: (batch_size, src_len, embed_dim)\n",
    "\n",
    "        # Reshape into multihead format\n",
    "        qE = qE.view(batch_size, tgt_len, self.num_heads, self.head_dim).transpose(1, 2) # shape: (batch_size, num_heads, tgt_len, head_dim)\n",
    "        kE = kE.view(batch_size, src_len, self.num_heads, self.head_dim).transpose(1, 2) # shape: (batch_size, num_heads, src_len, head_dim)\n",
    "        vE = vE.view(batch_size, src_len, self.num_heads, self.head_dim).transpose(1, 2) # shape: (batch_size, num_heads, src_len, 1)\n",
    "\n",
    "        attn_E = F.softmax(torch.matmul(qE, kE.transpose(-2, -1)) / self.scaling, dim=-1) # shape: (batch_size, num_heads, tgt_len, src_len)\n",
    "        attn_E = self.dropout(attn_E) \n",
    "        attn_E_output = torch.matmul(attn_E, vE) # shape: (batch_size, num_heads, tgt_len, head_dim)\n",
    "\n",
    "        # Reshape back to original dimensions\n",
    "        attn_E_output = attn_E_output.transpose(1, 2).contiguous().view(batch_size, tgt_len, self.embed_dim) # shape: (batch_size, tgt_len, embed_dim)\n",
    "        E_output = self.oE_proj(attn_E_output) # shape: (batch_size, tgt_len, embed_dim)\n",
    "        E_output = E_output.mean(1)\n",
    "\n",
    "        return w_output, E_output\n",
    "\n",
    "\n",
    "class DOFEN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        category_column_count: List[int],\n",
    "        n_class: int, \n",
    "        m: int = 16, \n",
    "        d: int = 4, \n",
    "        n_head: int = 1,\n",
    "        n_forest: int = 100,\n",
    "        n_hidden: int = 128,\n",
    "        dropout: float = 0.0, \n",
    "        categorical_optimized: bool = False,\n",
    "        fast_mode: int = 2048,\n",
    "        use_bagging_loss: bool = False,\n",
    "        device=torch.device('cuda'),\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.device = device\n",
    "        self.n_class = 1 if n_class == -1 else n_class\n",
    "        self.is_rgr = True if n_class == -1 else False\n",
    "\n",
    "        self.m = m\n",
    "        self.d = d\n",
    "        self.n_head = n_head\n",
    "        self.n_forest = n_forest\n",
    "        self.n_hidden = n_hidden\n",
    "        self.dropout = dropout\n",
    "        self.use_bagging_loss = use_bagging_loss\n",
    "\n",
    "        self.n_cond = self.d * self.m\n",
    "        self.n_col = len(category_column_count)\n",
    "        self.n_rodt = self.n_cond * self.n_col // self.d\n",
    "        self.n_estimator = max(2, int(self.n_col ** 0.5)) * self.n_cond // self.d\n",
    "\n",
    "        self.condition_generation = ConditionGeneration(            \n",
    "            category_column_count, \n",
    "            n_cond=self.n_cond,\n",
    "            n_hidden=self.n_hidden,\n",
    "            categorical_optimized=categorical_optimized, \n",
    "            fast_mode=fast_mode,\n",
    "        )\n",
    "\n",
    "        self.proj = nn.Linear(1, self.n_hidden)\n",
    "        self.rodt_construction = rODTConstruction(\n",
    "            self.n_cond,\n",
    "            self.n_col,\n",
    "            self.d,\n",
    "        )\n",
    "\n",
    "        self.norm = nn.LayerNorm(n_hidden)\n",
    "        self.attn = MultiheadAttention(\n",
    "            embed_dim=self.n_hidden,\n",
    "            num_heads=n_head,\n",
    "            dropout=0.2,\n",
    "        )\n",
    "\n",
    "        self.rodt_forest_construction = rODTForestConstruction(\n",
    "            self.n_col, \n",
    "            self.n_rodt, \n",
    "            self.n_cond,\n",
    "            self.n_estimator,\n",
    "            n_head=self.n_head, \n",
    "            n_hidden=self.n_hidden,\n",
    "            n_forest=self.n_forest,\n",
    "            dropout=self.dropout,\n",
    "            fast_mode=fast_mode,\n",
    "            device=self.device\n",
    "        )\n",
    "        self.rodt_forest_bagging = rODTForestBagging(\n",
    "            self.n_hidden,\n",
    "            self.dropout,\n",
    "            self.n_class\n",
    "        )\n",
    "\n",
    "        self.ffn_dropout_rate = 0.1\n",
    "        self.act = ReGLU()\n",
    "\n",
    "    def compute_loss(self, y_hat: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def evaluate(self, X: torch.Tensor, y: torch.Tensor) -> Dict[str, torch.Tensor]:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def forward(self, x: torch.Tensor, y: Optional[torch.Tensor] = None):\n",
    "        M = self.condition_generation(x)           # (b, n_cond, n_col, n_hidden)\n",
    "        # M = M.unsqueeze(-1)                        # (b, n_cond, n_col, 1)\n",
    "        # M = self.proj(M)                           # (b, n_cond, n_col, n_hidden)\n",
    "        O = self.rodt_construction(M)              # (b, n_rodt, d, n_hidden)\n",
    "        O = O.reshape(-1, self.d, self.n_hidden)   # (b * n_rodt, d, n_hidden)\n",
    "        O = self.norm(O)\n",
    "        w, E = self.attn(O, O, O)\n",
    "\n",
    "        w = w.reshape(-1, self.n_rodt, 1)\n",
    "        E = E.reshape(-1, self.n_rodt, self.n_hidden)\n",
    "\n",
    "        E_norm = E / E.norm(dim=-1, keepdim=True)\n",
    "        sim_loss = torch.einsum('bij,bjk->bik', E_norm, E_norm.permute(0, 2, 1))\n",
    "\n",
    "        F = self.rodt_forest_construction(w, E) # (b, n_forest, n_hidden)\n",
    "        y_hats = self.rodt_forest_bagging(F)    # (b, n_rodt, n_class)\n",
    "        y_hat = y_hats.mean(1)                  # (b, n_class)\n",
    "\n",
    "        if y is not None:\n",
    "            loss = self.compute_loss(\n",
    "                y_hats.permute(0, 2, 1) if not self.is_rgr else y_hats, \n",
    "                y.unsqueeze(-1).expand(-1, self.n_forest)\n",
    "            ) #+  sim_loss.abs().mean()\n",
    "            if self.n_forest > 1 and self.training and self.use_bagging_loss:\n",
    "                loss += self.compute_loss(y_hat, y)\n",
    "            return {'pred': y_hat, 'loss': loss}\n",
    "        return {'pred': y_hat}\n",
    "\n",
    "    def predict(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.forward(x)['pred']\n",
    "\n",
    "\n",
    "class DOFENClassifier(BaseClassifier, DOFEN):\n",
    "    def __init__(\n",
    "        self,\n",
    "        category_column_count: List[int],\n",
    "        n_class: int, \n",
    "        m: int = 16,\n",
    "        d: int = 4,\n",
    "        n_head: int = 4,\n",
    "        n_forest: int = 100,\n",
    "        n_hidden: int = 16,\n",
    "        dropout: float = 0.0, \n",
    "        categorical_optimized: bool = False,\n",
    "        fast_mode: int = 2048,\n",
    "        use_bagging_loss: bool = False,\n",
    "        device=torch.device('cuda'),\n",
    "    ) -> None:\n",
    "\n",
    "        super().__init__(\n",
    "            category_column_count=category_column_count, \n",
    "            n_class=n_class, \n",
    "            m=m, \n",
    "            d=d, \n",
    "            n_head=n_head,\n",
    "            n_forest=n_forest,\n",
    "            n_hidden=n_hidden,\n",
    "            dropout=dropout, \n",
    "            categorical_optimized=categorical_optimized,\n",
    "            fast_mode=fast_mode,\n",
    "            use_bagging_loss=use_bagging_loss,\n",
    "            device=device,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/300 [00:01<08:54,  1.79s/it, selected_test_score=0.583]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 1, 'valid_accuracy': 0.58528, 'best_valid_epoch': 1, 'best_valid_score': 0.58528, 'test_accuracy': 0.58318, 'selected_test_score': 0.58318}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/300 [00:03<08:51,  1.78s/it, selected_test_score=0.583]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 2, 'valid_accuracy': 0.58652, 'best_valid_epoch': 2, 'best_valid_score': 0.58652, 'test_accuracy': 0.58254, 'selected_test_score': 0.58254}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/300 [00:05<08:57,  1.81s/it, selected_test_score=0.623]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 3, 'valid_accuracy': 0.62584, 'best_valid_epoch': 3, 'best_valid_score': 0.62584, 'test_accuracy': 0.6226, 'selected_test_score': 0.6226}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 4/300 [00:07<08:52,  1.80s/it, selected_test_score=0.632]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 4, 'valid_accuracy': 0.6338, 'best_valid_epoch': 4, 'best_valid_score': 0.6338, 'test_accuracy': 0.63182, 'selected_test_score': 0.63182}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 5/300 [00:08<08:48,  1.79s/it, selected_test_score=0.634]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 5, 'valid_accuracy': 0.63818, 'best_valid_epoch': 5, 'best_valid_score': 0.63818, 'test_accuracy': 0.63388, 'selected_test_score': 0.63388}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 6/300 [00:10<08:45,  1.79s/it, selected_test_score=0.654]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 6, 'valid_accuracy': 0.65716, 'best_valid_epoch': 6, 'best_valid_score': 0.65716, 'test_accuracy': 0.65448, 'selected_test_score': 0.65448}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 7/300 [00:12<08:49,  1.81s/it, selected_test_score=0.665]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 7, 'valid_accuracy': 0.6677, 'best_valid_epoch': 7, 'best_valid_score': 0.6677, 'test_accuracy': 0.66542, 'selected_test_score': 0.66542}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 8/300 [00:14<08:44,  1.80s/it, selected_test_score=0.674]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 8, 'valid_accuracy': 0.67396, 'best_valid_epoch': 8, 'best_valid_score': 0.67396, 'test_accuracy': 0.67352, 'selected_test_score': 0.67352}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 9/300 [00:16<08:41,  1.79s/it, selected_test_score=0.69] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 9, 'valid_accuracy': 0.69098, 'best_valid_epoch': 9, 'best_valid_score': 0.69098, 'test_accuracy': 0.69034, 'selected_test_score': 0.69034}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 10/300 [00:17<08:43,  1.81s/it, selected_test_score=0.698]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 10, 'valid_accuracy': 0.70032, 'best_valid_epoch': 10, 'best_valid_score': 0.70032, 'test_accuracy': 0.69798, 'selected_test_score': 0.69798}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 11/300 [00:19<08:39,  1.80s/it, selected_test_score=0.703]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 11, 'valid_accuracy': 0.70426, 'best_valid_epoch': 11, 'best_valid_score': 0.70426, 'test_accuracy': 0.70304, 'selected_test_score': 0.70304}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 12/300 [00:21<08:36,  1.79s/it, selected_test_score=0.711]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 12, 'valid_accuracy': 0.71224, 'best_valid_epoch': 12, 'best_valid_score': 0.71224, 'test_accuracy': 0.7109, 'selected_test_score': 0.7109}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 13/300 [00:23<08:33,  1.79s/it, selected_test_score=0.711]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 13, 'valid_accuracy': 0.71186, 'best_valid_epoch': 12, 'best_valid_score': 0.71224, 'test_accuracy': 0.70906, 'selected_test_score': 0.7109}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 14/300 [00:25<08:35,  1.80s/it, selected_test_score=0.715]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 14, 'valid_accuracy': 0.71782, 'best_valid_epoch': 14, 'best_valid_score': 0.71782, 'test_accuracy': 0.71456, 'selected_test_score': 0.71456}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 15/300 [00:26<08:32,  1.80s/it, selected_test_score=0.718]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 15, 'valid_accuracy': 0.72146, 'best_valid_epoch': 15, 'best_valid_score': 0.72146, 'test_accuracy': 0.71816, 'selected_test_score': 0.71816}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 16/300 [00:28<08:28,  1.79s/it, selected_test_score=0.72] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 16, 'valid_accuracy': 0.72358, 'best_valid_epoch': 16, 'best_valid_score': 0.72358, 'test_accuracy': 0.7202, 'selected_test_score': 0.7202}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 17/300 [00:30<08:30,  1.81s/it, selected_test_score=0.721]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 17, 'valid_accuracy': 0.72392, 'best_valid_epoch': 17, 'best_valid_score': 0.72392, 'test_accuracy': 0.72112, 'selected_test_score': 0.72112}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 18/300 [00:32<08:27,  1.80s/it, selected_test_score=0.724]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 18, 'valid_accuracy': 0.72708, 'best_valid_epoch': 18, 'best_valid_score': 0.72708, 'test_accuracy': 0.7238, 'selected_test_score': 0.7238}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 19/300 [00:34<08:23,  1.79s/it, selected_test_score=0.724]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 19, 'valid_accuracy': 0.7284, 'best_valid_epoch': 19, 'best_valid_score': 0.7284, 'test_accuracy': 0.72432, 'selected_test_score': 0.72432}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 20/300 [00:35<08:21,  1.79s/it, selected_test_score=0.726]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 20, 'valid_accuracy': 0.73004, 'best_valid_epoch': 20, 'best_valid_score': 0.73004, 'test_accuracy': 0.72556, 'selected_test_score': 0.72556}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 21/300 [00:37<08:23,  1.80s/it, selected_test_score=0.729]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 21, 'valid_accuracy': 0.7309, 'best_valid_epoch': 21, 'best_valid_score': 0.7309, 'test_accuracy': 0.72926, 'selected_test_score': 0.72926}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 22/300 [00:39<08:19,  1.80s/it, selected_test_score=0.731]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 22, 'valid_accuracy': 0.73154, 'best_valid_epoch': 22, 'best_valid_score': 0.73154, 'test_accuracy': 0.73074, 'selected_test_score': 0.73074}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 22/300 [00:41<08:41,  1.88s/it, selected_test_score=0.731]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 42\u001b[0m\n\u001b[1;32m     32\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     34\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     35\u001b[0m     model,\n\u001b[1;32m     36\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mbatch_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     40\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     41\u001b[0m )\n\u001b[0;32m---> 42\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_X\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_X\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_y\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_X\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_y\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/github/Differential-FT-Transformer/src/trainer.py:144\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, train_X, train_y, valid_X, valid_y, test_X, test_y)\u001b[0m\n\u001b[1;32m    141\u001b[0m     all_results \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m valid_results\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m test_loader \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m     test_results \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m: value \u001b[38;5;28;01mfor\u001b[39;00m metric, value \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m curr_epoch \u001b[38;5;241m==\u001b[39m best_valid_epoch:\n",
      "File \u001b[0;32m~/dftt/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/github/Differential-FT-Transformer/src/trainer.py:60\u001b[0m, in \u001b[0;36mTrainer.test\u001b[0;34m(self, test_loader)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     59\u001b[0m preds, labels \u001b[38;5;241m=\u001b[39m [], []\n\u001b[0;32m---> 60\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X, y \u001b[38;5;129;01min\u001b[39;00m test_loader:\n\u001b[1;32m     61\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mpredict(X\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice))\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     62\u001b[0m     preds\u001b[38;5;241m.\u001b[39mappend(pred)\n",
      "File \u001b[0;32m~/dftt/lib/python3.10/site-packages/torch/utils/data/dataloader.py:708\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 708\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    712\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    713\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    714\u001b[0m ):\n",
      "File \u001b[0;32m~/dftt/lib/python3.10/site-packages/torch/utils/data/dataloader.py:764\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    763\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 764\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    766\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/dftt/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/dftt/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/dftt/lib/python3.10/site-packages/torch/utils/data/dataset.py:211\u001b[0m, in \u001b[0;36mTensorDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[0;32m--> 211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dftt/lib/python3.10/site-packages/torch/utils/data/dataset.py:211\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[0;32m--> 211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(tensor[index] \u001b[38;5;28;01mfor\u001b[39;00m tensor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensors)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "args = Config()\n",
    "set_random_seed()\n",
    "\n",
    "data_dict = load_pkl_data(Path(args.data_dir, args.data_id, '0.pkl'))\n",
    "n_class = data_dict['label_cat_count']\n",
    "task = 'r' if n_class == -1 else 'c'\n",
    "\n",
    "target_transform = args.target_transform if task == 'r' else False\n",
    "train_X = data_dict['x_train']\n",
    "train_y = data_dict['y_train' if not target_transform else 'y_train_transform']\n",
    "valid_X = data_dict['x_val']\n",
    "valid_y = data_dict['y_val' if not target_transform else 'y_val_transform']\n",
    "test_X = data_dict['x_test']\n",
    "test_y = data_dict['y_test' if not target_transform else 'y_test_transform']\n",
    "\n",
    "data_args = {\n",
    "    'n_feature': train_X.shape[1],\n",
    "    'n_train': train_X.shape[0],\n",
    "    'n_valid': valid_X.shape[0],\n",
    "    'n_test': test_X.shape[0],\n",
    "}\n",
    "\n",
    "model_params = {\n",
    "    'category_column_count': data_dict['col_cat_count'],\n",
    "}\n",
    "if n_class != -1:\n",
    "    model_params['n_class'] = n_class\n",
    "\n",
    "\n",
    "model = DOFENClassifier(**model_params)\n",
    "eval_funs = cls_eval_funs\n",
    "metrics = 'accuracy'\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    batch_size=args.batch_size,\n",
    "    n_epoch=args.n_epoch,\n",
    "    eval_funs=eval_funs,\n",
    "    metric=metrics,\n",
    "    verbose=True,\n",
    ")\n",
    "trainer.fit(\n",
    "    train_X=train_X, train_y=train_y,\n",
    "    valid_X=valid_X, valid_y=valid_y,\n",
    "    test_X=test_X, test_y=test_y,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DOFENClassifier(\n",
       "  (condition_generation): ConditionGeneration(\n",
       "    (phi_1): ModuleDict(\n",
       "      (num): Sequential(\n",
       "        (0): Reshape()\n",
       "        (1): FastGroupConv1d(10, 10240, kernel_size=(1,), stride=(1,), groups=10)\n",
       "        (2): Reshape()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (proj): Linear(in_features=1, out_features=16, bias=True)\n",
       "  (rodt_construction): rODTConstruction()\n",
       "  (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "  (attn): MultiheadAttention(\n",
       "    (qw_proj): Linear(in_features=16, out_features=16, bias=True)\n",
       "    (kw_proj): Linear(in_features=16, out_features=16, bias=True)\n",
       "    (vw_proj): Linear(in_features=16, out_features=16, bias=True)\n",
       "    (ow_proj): Linear(in_features=16, out_features=1, bias=True)\n",
       "    (qE_proj): Linear(in_features=16, out_features=16, bias=True)\n",
       "    (kE_proj): Linear(in_features=16, out_features=16, bias=True)\n",
       "    (vE_proj): Linear(in_features=16, out_features=16, bias=True)\n",
       "    (oE_proj): Linear(in_features=16, out_features=16, bias=True)\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (rodt_forest_construction): rODTForestConstruction()\n",
       "  (rodt_forest_bagging): rODTForestBagging(\n",
       "    (phi_3): Sequential(\n",
       "      (0): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "      (1): Dropout(p=0.0, inplace=False)\n",
       "      (2): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "      (5): Dropout(p=0.0, inplace=False)\n",
       "      (6): Linear(in_features=16, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (act): ReGLU()\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiheadAttention(\n",
       "  (qw_proj): Linear(in_features=16, out_features=16, bias=True)\n",
       "  (kw_proj): Linear(in_features=16, out_features=16, bias=True)\n",
       "  (vw_proj): Linear(in_features=16, out_features=16, bias=True)\n",
       "  (ow_proj): Linear(in_features=16, out_features=1, bias=True)\n",
       "  (qE_proj): Linear(in_features=16, out_features=16, bias=True)\n",
       "  (kE_proj): Linear(in_features=16, out_features=16, bias=True)\n",
       "  (vE_proj): Linear(in_features=16, out_features=16, bias=True)\n",
       "  (oE_proj): Linear(in_features=16, out_features=16, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pred': tensor([[ 0.3960,  0.2966],\n",
       "         [-0.3075,  0.4038],\n",
       "         [ 0.2521, -0.0345],\n",
       "         [-0.5294,  0.9460],\n",
       "         [-0.6331,  0.6158],\n",
       "         [-0.2786,  0.4342],\n",
       "         [ 0.5308,  0.0683],\n",
       "         [ 1.0910, -0.3817],\n",
       "         [-0.5125,  0.6734],\n",
       "         [ 0.2061,  0.2704],\n",
       "         [-0.3352,  0.3928],\n",
       "         [ 0.1079,  0.3883],\n",
       "         [ 1.5631, -1.1562],\n",
       "         [-0.7646,  0.6758],\n",
       "         [ 2.2875, -1.7891],\n",
       "         [-0.5398,  0.3726],\n",
       "         [-0.1332,  0.5100],\n",
       "         [ 0.7137, -0.0575],\n",
       "         [-0.8001,  0.7812],\n",
       "         [ 1.7682, -1.1256],\n",
       "         [-0.9896,  0.5423],\n",
       "         [ 1.9622, -1.7037],\n",
       "         [-0.6393,  0.6541],\n",
       "         [ 1.7233, -1.4720],\n",
       "         [-0.8367,  0.9338],\n",
       "         [ 0.2391,  0.3703],\n",
       "         [-0.0406,  0.5239],\n",
       "         [ 0.3454,  0.0383],\n",
       "         [-0.8716,  0.7052],\n",
       "         [-0.3691,  0.1509],\n",
       "         [-0.9906,  0.8783],\n",
       "         [ 0.3124,  0.1143],\n",
       "         [-0.6862,  0.7564],\n",
       "         [-0.5726,  0.5572],\n",
       "         [-0.4090,  0.8230],\n",
       "         [ 0.1618,  0.3974],\n",
       "         [ 1.9192, -1.3941],\n",
       "         [ 0.2682,  0.1283],\n",
       "         [ 2.2882, -1.4577],\n",
       "         [ 1.6652, -1.3438],\n",
       "         [-0.9437,  0.8919],\n",
       "         [-0.4476,  0.7800],\n",
       "         [-0.6308,  0.5440],\n",
       "         [ 0.8543, -0.2860],\n",
       "         [-0.6834,  0.7526],\n",
       "         [-1.0156,  0.6620],\n",
       "         [-0.7877,  0.8689],\n",
       "         [-0.0479,  0.2779],\n",
       "         [ 0.2447,  0.1691],\n",
       "         [-0.2649,  0.4459],\n",
       "         [ 0.9892, -0.4293],\n",
       "         [ 0.6722, -0.0908],\n",
       "         [ 0.0330,  0.2956],\n",
       "         [-0.0602,  0.5553],\n",
       "         [ 0.0799,  0.2118],\n",
       "         [-0.1205,  0.6432],\n",
       "         [-0.9703,  1.0976],\n",
       "         [-0.7333,  0.9647],\n",
       "         [ 0.0229,  0.1647],\n",
       "         [-0.7687,  0.8523],\n",
       "         [-0.6110,  0.6810],\n",
       "         [ 2.3443, -1.6591],\n",
       "         [ 1.2797, -0.6823],\n",
       "         [ 0.9870, -0.4960],\n",
       "         [ 1.2742, -0.7153],\n",
       "         [-0.9253,  0.5334],\n",
       "         [-0.1037,  0.6408],\n",
       "         [ 0.8769, -0.1268],\n",
       "         [-0.9723,  0.5694],\n",
       "         [ 1.8928, -1.3573],\n",
       "         [-0.4259,  0.7704],\n",
       "         [-0.6914,  0.5825],\n",
       "         [ 1.8087, -1.0285],\n",
       "         [ 2.1569, -1.5470],\n",
       "         [ 0.2163, -0.0959],\n",
       "         [-0.9453,  1.0490],\n",
       "         [-0.7818,  0.6683],\n",
       "         [ 1.5551, -0.8888],\n",
       "         [-0.6147,  0.8366],\n",
       "         [-0.3994,  0.5041],\n",
       "         [ 0.2765,  0.2741],\n",
       "         [-0.5198,  0.8258],\n",
       "         [ 0.0644,  0.3518],\n",
       "         [ 1.7697, -1.1681],\n",
       "         [-0.8076,  1.1973],\n",
       "         [-0.9665,  1.0599],\n",
       "         [-0.6415,  0.9515],\n",
       "         [-0.1066,  0.3359],\n",
       "         [-1.0790,  0.8201],\n",
       "         [-0.7806,  0.7258],\n",
       "         [-0.6011,  0.9424],\n",
       "         [-0.9542,  0.9067],\n",
       "         [ 1.1799, -0.7271],\n",
       "         [ 1.8906, -1.2911],\n",
       "         [ 0.4582, -0.0281],\n",
       "         [ 1.1639, -0.7329],\n",
       "         [ 1.0522, -0.3759],\n",
       "         [-0.3336,  0.6868],\n",
       "         [ 2.1777, -1.3356],\n",
       "         [ 1.6667, -0.7634],\n",
       "         [-0.4584,  0.5177],\n",
       "         [ 0.1365,  0.3990],\n",
       "         [-0.5791,  0.7406],\n",
       "         [-1.0153,  1.1213],\n",
       "         [ 1.1685, -0.7574],\n",
       "         [ 0.3436,  0.2587],\n",
       "         [ 0.3370,  0.0896],\n",
       "         [-0.6134,  0.8692],\n",
       "         [ 0.4467,  0.0819],\n",
       "         [-0.4652,  0.7245],\n",
       "         [-0.8046,  1.1273],\n",
       "         [-0.7989,  0.9403],\n",
       "         [ 0.1192,  0.4274],\n",
       "         [-1.0711,  0.6402],\n",
       "         [-0.4889,  0.4148],\n",
       "         [-0.1194,  0.5593],\n",
       "         [ 1.5752, -0.9578],\n",
       "         [ 0.1976,  0.2487],\n",
       "         [-1.0362,  1.0516],\n",
       "         [-0.9190,  1.0390],\n",
       "         [ 1.7676, -1.3783],\n",
       "         [-0.9760,  1.0152],\n",
       "         [-0.7883,  0.7173],\n",
       "         [ 0.1505,  0.4374],\n",
       "         [ 0.2007,  0.3423],\n",
       "         [-0.8543,  0.6263],\n",
       "         [ 0.0654,  0.4347],\n",
       "         [-0.8667,  0.6072],\n",
       "         [-0.6616,  0.9376],\n",
       "         [-0.7687,  0.5281],\n",
       "         [-1.0219,  0.6788],\n",
       "         [-0.5458,  0.8126],\n",
       "         [-0.6841,  0.6769],\n",
       "         [ 0.7670, -0.2730],\n",
       "         [-0.6838,  0.6294],\n",
       "         [-0.8418,  1.0799],\n",
       "         [ 0.5962, -0.0133],\n",
       "         [-0.4623,  0.6046],\n",
       "         [ 1.3001, -0.4888],\n",
       "         [-0.3961,  0.5096],\n",
       "         [ 1.5643, -1.1097],\n",
       "         [-0.7710,  0.8969],\n",
       "         [ 0.6670, -0.1107],\n",
       "         [ 1.3910, -0.8251],\n",
       "         [ 0.7162, -0.2841],\n",
       "         [-0.0547,  0.3609],\n",
       "         [-0.6042,  0.4884],\n",
       "         [-0.3224,  0.5033],\n",
       "         [ 1.6313, -0.7526],\n",
       "         [ 0.7474, -0.2469],\n",
       "         [-1.0330,  1.0808],\n",
       "         [ 0.8193, -0.3119],\n",
       "         [-0.2526,  0.6799],\n",
       "         [-0.9449,  1.1137],\n",
       "         [ 1.0835, -0.5567],\n",
       "         [-0.8394,  0.8175],\n",
       "         [ 0.8380, -0.4185],\n",
       "         [-0.8480,  1.1046],\n",
       "         [ 1.2243, -0.7603],\n",
       "         [ 0.0588,  0.2852],\n",
       "         [ 2.2287, -1.6761],\n",
       "         [-0.6076,  0.6294],\n",
       "         [ 0.5486,  0.0077],\n",
       "         [-0.9057,  0.7577],\n",
       "         [-0.5072,  1.0598],\n",
       "         [ 0.6916, -0.0206],\n",
       "         [-0.8800,  0.9935],\n",
       "         [ 0.9003, -0.6233],\n",
       "         [ 1.1412, -0.6431],\n",
       "         [ 0.8474, -0.1870],\n",
       "         [ 0.6627,  0.0346],\n",
       "         [-0.7918,  0.6968],\n",
       "         [-0.6547,  0.7057],\n",
       "         [ 0.8300, -0.3524],\n",
       "         [-1.0172,  1.0220],\n",
       "         [ 1.3467, -0.8025],\n",
       "         [ 2.1866, -1.4088],\n",
       "         [ 0.3849,  0.1610],\n",
       "         [-0.9462,  0.9550],\n",
       "         [ 0.6067,  0.0150],\n",
       "         [-0.3865,  0.6333],\n",
       "         [ 2.2871, -1.6960],\n",
       "         [ 1.3675, -0.8885],\n",
       "         [-0.0597,  0.1659],\n",
       "         [ 0.5696, -0.0250],\n",
       "         [ 0.4678,  0.0290],\n",
       "         [-0.3020,  0.4608],\n",
       "         [ 0.3371,  0.2852],\n",
       "         [-0.0195,  0.3503],\n",
       "         [-1.0845,  0.7949],\n",
       "         [ 1.3781, -0.8409],\n",
       "         [ 0.3069,  0.1359],\n",
       "         [ 0.6488, -0.0984],\n",
       "         [-0.5703,  0.7307],\n",
       "         [ 0.9323, -0.3719],\n",
       "         [-0.7737,  0.9690],\n",
       "         [-0.5771,  0.8292],\n",
       "         [ 1.1391, -0.4799],\n",
       "         [ 0.3583,  0.2416],\n",
       "         [-0.9335,  0.7525],\n",
       "         [ 0.7837, -0.0540],\n",
       "         [ 1.2764, -0.6875],\n",
       "         [-0.9700,  0.6769],\n",
       "         [-1.0667,  0.8650],\n",
       "         [ 0.7841, -0.3067],\n",
       "         [-0.6748,  0.3495],\n",
       "         [-0.7679,  0.6891],\n",
       "         [-0.8856,  0.7336],\n",
       "         [-0.5127,  0.5771],\n",
       "         [ 1.3709, -0.8120],\n",
       "         [ 1.7881, -1.2103],\n",
       "         [-0.8797,  0.9542],\n",
       "         [ 0.7342, -0.1448],\n",
       "         [ 0.5485, -0.0205],\n",
       "         [ 2.3704, -1.7566],\n",
       "         [-1.1802,  0.7553],\n",
       "         [ 1.6796, -1.0395],\n",
       "         [-0.5468,  0.3042],\n",
       "         [-0.6832,  0.4726],\n",
       "         [ 0.8958, -0.1587],\n",
       "         [-0.5033,  0.4644],\n",
       "         [ 1.2450, -0.5870],\n",
       "         [ 1.4074, -0.7232],\n",
       "         [ 2.1256, -1.4110],\n",
       "         [ 1.7883, -1.2783],\n",
       "         [-0.9221,  0.8669],\n",
       "         [ 1.4152, -0.7604],\n",
       "         [-0.8304,  0.7472],\n",
       "         [ 1.1865, -0.5911],\n",
       "         [ 0.9562, -0.3115],\n",
       "         [-0.1796,  0.4406],\n",
       "         [-1.1618,  0.7756],\n",
       "         [-0.6465,  0.5368],\n",
       "         [ 0.6478, -0.0214],\n",
       "         [ 1.1886, -0.6589],\n",
       "         [-0.5699,  0.6853],\n",
       "         [-0.9946,  0.8787],\n",
       "         [-1.0675,  0.7659],\n",
       "         [ 0.4770,  0.0330],\n",
       "         [-0.8347,  0.6392],\n",
       "         [ 1.8190, -1.3698],\n",
       "         [ 2.2818, -1.6744],\n",
       "         [-0.0808,  0.2466],\n",
       "         [-0.0536,  0.4607],\n",
       "         [ 1.1934, -0.8427],\n",
       "         [-0.7860,  1.0703],\n",
       "         [-0.4079,  0.7550],\n",
       "         [ 2.0905, -1.4442],\n",
       "         [ 0.1749,  0.2562],\n",
       "         [-1.0522,  0.6882],\n",
       "         [-0.5617,  0.6597],\n",
       "         [ 1.7888, -1.1578],\n",
       "         [-0.9771,  1.1907],\n",
       "         [-0.8279,  1.0512],\n",
       "         [-0.8600,  0.8744],\n",
       "         [-0.2232,  0.4372]], device='cuda:0', grad_fn=<MeanBackward1>)}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()(torch.tensor(train_X[:256]).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = {}\n",
    "\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activations[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "handle = model.get_submodule(\"attn.oE_proj\").register_forward_hook(get_activation(\"oE_proj\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pred': tensor([[-0.1647,  0.6241],\n",
       "         [-1.2888,  1.3635],\n",
       "         [-0.7934,  0.9415],\n",
       "         [-1.4424,  1.5319],\n",
       "         [-1.0155,  1.0836],\n",
       "         [-1.0390,  1.2782],\n",
       "         [-0.2088,  0.7644],\n",
       "         [-1.1447,  1.2297],\n",
       "         [-1.1862,  1.3229],\n",
       "         [-0.8219,  1.0915],\n",
       "         [-0.5778,  0.8187],\n",
       "         [-0.4195,  0.8935],\n",
       "         [-0.2086,  0.7363],\n",
       "         [-0.9380,  1.0292],\n",
       "         [-0.3617,  0.8094],\n",
       "         [-0.7664,  1.1210],\n",
       "         [-0.0642,  0.6315],\n",
       "         [-1.2997,  1.4078],\n",
       "         [-1.4671,  1.5043],\n",
       "         [ 0.2227,  0.3196],\n",
       "         [-1.3820,  1.5328],\n",
       "         [-0.4204,  0.8093],\n",
       "         [-0.1210,  0.6234],\n",
       "         [-0.6125,  0.9705],\n",
       "         [-1.0423,  1.2774],\n",
       "         [-0.5666,  0.9664],\n",
       "         [ 0.0381,  0.4372],\n",
       "         [-1.0460,  1.2743],\n",
       "         [-0.6940,  0.9555],\n",
       "         [-1.1396,  1.0931],\n",
       "         [-0.1255,  0.5501],\n",
       "         [-0.8774,  1.1176],\n",
       "         [-0.2448,  0.7247],\n",
       "         [-0.9834,  1.2011],\n",
       "         [-0.2099,  0.6597],\n",
       "         [ 0.0200,  0.4664],\n",
       "         [-0.3982,  0.7336],\n",
       "         [-0.2089,  0.7045],\n",
       "         [-0.7240,  1.1975],\n",
       "         [-0.4232,  0.8012],\n",
       "         [-1.1649,  1.4112],\n",
       "         [-0.5002,  0.7745],\n",
       "         [-0.4058,  0.7558],\n",
       "         [-1.1824,  1.3820],\n",
       "         [-0.6117,  0.9825],\n",
       "         [-1.1106,  1.4079],\n",
       "         [-1.2540,  1.3887],\n",
       "         [ 0.7030,  0.1301],\n",
       "         [-1.1354,  1.2706],\n",
       "         [-0.3687,  0.7887],\n",
       "         [-0.4632,  0.9069],\n",
       "         [ 0.7068,  0.1288],\n",
       "         [-0.8248,  0.9433],\n",
       "         [-0.9120,  1.0461],\n",
       "         [-1.1526,  1.2408],\n",
       "         [-0.9127,  1.2887],\n",
       "         [-1.0912,  1.0964],\n",
       "         [-0.7279,  0.8885],\n",
       "         [-0.6826,  1.0391],\n",
       "         [-0.2940,  0.6714],\n",
       "         [-0.3092,  0.6413],\n",
       "         [-0.3322,  0.7290],\n",
       "         [-0.6020,  0.9720],\n",
       "         [-0.9692,  1.2116],\n",
       "         [-0.6970,  0.9094],\n",
       "         [-0.8107,  1.0694],\n",
       "         [-0.2483,  0.7405],\n",
       "         [-0.3778,  0.6794],\n",
       "         [-1.1453,  1.2852],\n",
       "         [-1.1992,  1.4027],\n",
       "         [-0.9112,  1.1576],\n",
       "         [-1.0239,  1.2157],\n",
       "         [-0.5185,  0.9523],\n",
       "         [-1.2789,  1.5069],\n",
       "         [ 0.2649,  0.3815],\n",
       "         [-1.0469,  1.2424],\n",
       "         [-1.2828,  1.4219],\n",
       "         [-0.8692,  1.1823],\n",
       "         [-0.4937,  0.8833],\n",
       "         [-1.3910,  1.5881],\n",
       "         [-0.6372,  0.9204],\n",
       "         [-0.7782,  1.1049],\n",
       "         [-1.0206,  1.3701],\n",
       "         [-0.4520,  0.9173],\n",
       "         [-1.3311,  1.5255],\n",
       "         [-0.4449,  0.8278],\n",
       "         [-0.5104,  0.7754],\n",
       "         [-1.1262,  1.0904],\n",
       "         [ 0.0327,  0.4158],\n",
       "         [-0.9833,  1.2411],\n",
       "         [-1.1515,  1.2693],\n",
       "         [ 0.1251,  0.5434],\n",
       "         [-0.8556,  1.1239],\n",
       "         [-0.2837,  0.6891],\n",
       "         [-1.0411,  1.3822],\n",
       "         [-0.7940,  1.0108],\n",
       "         [-0.2821,  0.6535],\n",
       "         [-1.5290,  1.5964],\n",
       "         [-0.3903,  0.9009],\n",
       "         [-0.5267,  0.7788],\n",
       "         [-0.5408,  0.8093],\n",
       "         [-1.1147,  1.2581],\n",
       "         [-0.3709,  0.8971],\n",
       "         [ 0.0878,  0.4326],\n",
       "         [-1.0236,  1.2185],\n",
       "         [ 0.2743,  0.4352],\n",
       "         [-1.5053,  1.6556],\n",
       "         [-0.5372,  0.8920],\n",
       "         [-0.3806,  0.8017],\n",
       "         [-0.3153,  0.7938],\n",
       "         [-1.2210,  1.3463],\n",
       "         [-0.8272,  0.9409],\n",
       "         [-0.6365,  0.9398],\n",
       "         [-0.0358,  0.6364],\n",
       "         [-0.5840,  0.8893],\n",
       "         [-0.7807,  1.0545],\n",
       "         [-0.6248,  0.9404],\n",
       "         [-0.9261,  1.1014],\n",
       "         [-0.6482,  0.9514],\n",
       "         [-0.5208,  0.9097],\n",
       "         [-0.9258,  1.1452],\n",
       "         [-1.2670,  1.3940],\n",
       "         [ 0.0345,  0.5271],\n",
       "         [-0.6154,  0.8084],\n",
       "         [-1.4065,  1.5636],\n",
       "         [-0.6376,  0.9277],\n",
       "         [-1.2841,  1.3928],\n",
       "         [-1.0844,  1.1135],\n",
       "         [-0.7471,  0.9237],\n",
       "         [-0.6716,  0.8927],\n",
       "         [-0.9028,  1.1817],\n",
       "         [ 0.1287,  0.5057],\n",
       "         [-0.3459,  0.7219],\n",
       "         [-0.7873,  1.0207],\n",
       "         [-0.6602,  0.9018],\n",
       "         [-0.2995,  0.7061],\n",
       "         [-1.0121,  1.2306],\n",
       "         [-1.4349,  1.3884],\n",
       "         [-1.1702,  1.1109],\n",
       "         [-0.3996,  0.6700],\n",
       "         [-1.1490,  1.3273],\n",
       "         [-0.3870,  0.8274],\n",
       "         [-1.0870,  1.2260],\n",
       "         [-1.5546,  1.5770],\n",
       "         [-0.0930,  0.5747],\n",
       "         [-1.1661,  1.2866],\n",
       "         [-0.5432,  0.9271],\n",
       "         [-0.9780,  1.0551],\n",
       "         [-0.6340,  0.9728],\n",
       "         [-0.8504,  1.0095],\n",
       "         [-0.8073,  1.1070],\n",
       "         [-1.2099,  1.4516],\n",
       "         [-0.6730,  0.9582],\n",
       "         [-0.5762,  0.9298],\n",
       "         [-0.6521,  0.9254],\n",
       "         [-1.0961,  1.1694],\n",
       "         [-0.6643,  0.8552],\n",
       "         [-1.4327,  1.5608],\n",
       "         [ 0.2792,  0.4156],\n",
       "         [-0.0307,  0.5786],\n",
       "         [-0.8219,  0.9190],\n",
       "         [-1.0421,  1.2162],\n",
       "         [-0.3275,  0.7594],\n",
       "         [-0.6193,  0.8731],\n",
       "         [-0.4650,  0.7834],\n",
       "         [ 0.0123,  0.4344],\n",
       "         [ 0.1741,  0.3891],\n",
       "         [-0.8744,  1.2609],\n",
       "         [-0.5841,  0.9630],\n",
       "         [-1.1538,  1.3360],\n",
       "         [-0.4801,  0.7681],\n",
       "         [-0.2116,  0.5535],\n",
       "         [-1.2269,  1.4191],\n",
       "         [-1.4322,  1.5365],\n",
       "         [-0.5915,  0.9640],\n",
       "         [-0.8360,  1.0865],\n",
       "         [-1.0272,  1.0759],\n",
       "         [-0.6726,  0.9005],\n",
       "         [-1.1526,  1.2408],\n",
       "         [-0.2001,  0.5845],\n",
       "         [-1.6277,  1.6337],\n",
       "         [-0.5560,  0.9679],\n",
       "         [ 0.0129,  0.6004],\n",
       "         [-1.4127,  1.5264],\n",
       "         [-0.8510,  1.1237],\n",
       "         [-1.2284,  1.3461],\n",
       "         [-0.7414,  0.9630],\n",
       "         [-0.7376,  1.1146],\n",
       "         [-0.1334,  0.6783],\n",
       "         [-0.7085,  0.9339],\n",
       "         [-1.0514,  1.3088],\n",
       "         [-0.8772,  1.0991],\n",
       "         [-0.4552,  0.9577],\n",
       "         [-1.0769,  1.1753],\n",
       "         [-1.1241,  1.1386],\n",
       "         [-0.8859,  1.1282],\n",
       "         [-0.2843,  0.6578],\n",
       "         [-0.6312,  0.9804],\n",
       "         [-0.3716,  0.7856],\n",
       "         [-0.1274,  0.5581],\n",
       "         [-0.7077,  0.9294],\n",
       "         [-1.1953,  1.3143],\n",
       "         [-0.8267,  1.0616],\n",
       "         [-0.8024,  1.0905],\n",
       "         [-0.9285,  1.0826],\n",
       "         [-0.8075,  1.1308],\n",
       "         [-1.1317,  1.3305],\n",
       "         [-0.5552,  0.7665],\n",
       "         [-0.6387,  1.0071],\n",
       "         [-0.5963,  0.9070],\n",
       "         [-1.0325,  1.3799],\n",
       "         [ 0.5170,  0.2447],\n",
       "         [-1.1000,  1.2763],\n",
       "         [-0.1756,  0.6891],\n",
       "         [-0.2172,  0.6745],\n",
       "         [-0.1644,  0.6345],\n",
       "         [-0.6635,  0.9318],\n",
       "         [-0.7118,  0.9003],\n",
       "         [-0.4347,  0.7844],\n",
       "         [-1.1531,  1.4412],\n",
       "         [-0.1789,  0.5618],\n",
       "         [ 0.7108,  0.1475],\n",
       "         [-0.3853,  0.6371],\n",
       "         [-0.8706,  1.0959],\n",
       "         [-0.7407,  0.9918],\n",
       "         [-0.5561,  0.9161],\n",
       "         [-0.5885,  0.9476],\n",
       "         [ 0.3382,  0.3452],\n",
       "         [-0.5426,  0.8705],\n",
       "         [-0.6377,  0.9170],\n",
       "         [-0.9920,  1.2195],\n",
       "         [-0.6133,  0.8056],\n",
       "         [-0.5983,  0.9617],\n",
       "         [-0.1084,  0.7263],\n",
       "         [-0.8779,  1.3001],\n",
       "         [-1.0398,  1.2113],\n",
       "         [-0.9172,  1.1470],\n",
       "         [-0.4394,  0.7994],\n",
       "         [-1.3765,  1.5174],\n",
       "         [-0.5148,  0.8692],\n",
       "         [-1.1226,  1.2615],\n",
       "         [-0.8778,  1.1731],\n",
       "         [-1.4376,  1.6171],\n",
       "         [-0.7132,  1.1096],\n",
       "         [-0.4643,  0.8306],\n",
       "         [-0.7365,  1.0015],\n",
       "         [-1.5433,  1.5784],\n",
       "         [-0.8711,  1.1535],\n",
       "         [-0.8562,  1.1277],\n",
       "         [-0.3563,  0.8067],\n",
       "         [ 0.5062,  0.2665],\n",
       "         [-0.5826,  0.8397],\n",
       "         [ 0.0942,  0.5714],\n",
       "         [-0.8022,  1.1026],\n",
       "         [ 0.3952,  0.3597],\n",
       "         [-0.6475,  0.9205]], device='cuda:0', grad_fn=<MeanBackward1>)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()(torch.tensor(train_X[:256]).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40960, 4, 16])\n"
     ]
    }
   ],
   "source": [
    "oE_proj_output = activations[\"oE_proj\"]\n",
    "print(oE_proj_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "oE_proj_output = oE_proj_output.reshape(256, -1, 4, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 160, 4, 16])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oE_proj_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[112, -1]' is invalid for input of size 10240",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43moE_proj_output\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m112\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[112, -1]' is invalid for input of size 10240"
     ]
    }
   ],
   "source": [
    "x = oE_proj_output[0].view(112, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m x_ \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m \u001b[38;5;241m/\u001b[39m ((x \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.5\u001b[39m)[:, \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m      2\u001b[0m sim \u001b[38;5;241m=\u001b[39m x_ \u001b[38;5;241m@\u001b[39m x_\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m      3\u001b[0m sim\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "x_ = x / ((x ** 2).sum(dim=1) ** 0.5)[:, None]\n",
    "sim = x_ @ x_.T\n",
    "sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 0.9864, 0.9966, 0.9950, 0.9987, 0.9916, 0.8117, 0.9820, 0.8812,\n",
       "        0.9980, 0.8736, 0.9975, 0.9953, 0.7756, 0.8760, 0.9834, 0.8134, 0.9957,\n",
       "        0.9969, 0.9995, 0.9883, 0.9851, 0.9917, 0.9916, 0.9787, 0.8838, 0.9921,\n",
       "        0.9646, 0.9666, 0.9698, 0.9916, 0.9912, 0.9725, 0.8803, 0.8372, 0.9318,\n",
       "        0.9742, 0.8234, 0.9980, 0.9429, 0.9838, 0.9895, 0.8261, 0.9684, 0.9800,\n",
       "        0.7999, 0.8236, 0.7952, 0.7878, 0.9967, 0.9602, 0.9996, 0.9560, 0.8429,\n",
       "        0.9823, 0.9934, 0.9196, 0.9720, 0.8384, 0.9974, 0.9914, 0.9196, 0.9915,\n",
       "        0.9987, 0.9260, 0.9399, 0.9613, 0.9955, 0.9972, 0.9868, 0.8621, 0.9961,\n",
       "        0.9988, 0.9552, 0.9926, 0.9950, 0.9754, 0.8788, 0.9974, 0.8764, 0.9973,\n",
       "        0.8756, 0.7560, 0.9939, 0.9600, 0.9306, 0.9128, 0.9945, 0.9986, 0.9579,\n",
       "        0.8050, 0.8734, 0.8130, 0.9218, 0.9924, 0.9981, 0.9805, 0.8486, 0.9330,\n",
       "        0.9673, 0.8925, 0.9559, 0.9933, 0.9302, 0.8561, 0.8310, 0.8679, 0.9961,\n",
       "        0.9639, 0.8331, 0.9967, 0.9446], device='cuda:0')"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dftt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
